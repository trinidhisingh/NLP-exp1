{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V-fTT2za31nu"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1fZv_qn4yJg",
        "outputId": "2e579a59-df53-448f-9525-5de95bbe79c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())  # Convert to lowercase for consistency\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "QwK5sxAe4av-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(tokens, text):\n",
        "    # Vectorization\n",
        "    vectorizer = CountVectorizer()\n",
        "    token_matrix = vectorizer.fit_transform([\" \".join(tokens), text])  # Create a matrix of token counts\n",
        "    return token_matrix"
      ],
      "metadata": {
        "id": "TGAKOAmY4d-e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text, top_n=2):\n",
        "    sentences = sent_tokenize(text)\n",
        "    tokens = preprocess(text)\n",
        "\n",
        "    token_matrix = vectorize(tokens, text)\n",
        "\n",
        "    similarity = cosine_similarity(token_matrix)[0]  # Calculate similarity between the tokenized text and each sentence\n",
        "    print(\"Vector Similarity Scores:\")\n",
        "    for i, score in enumerate(similarity):\n",
        "        print(f\"Sentence {i+1}: {score}\")\n",
        "\n",
        "    top_indices = similarity.argsort()[-top_n:][::-1]  # Get indices of most similar sentences\n",
        "    summary = [sentences[i] for i in top_indices]  # Extract most similar sentences\n",
        "\n",
        "    return ' '.join(summary)"
      ],
      "metadata": {
        "id": "oXUUFdxe4hES"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter your text:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn1RREol4kvK",
        "outputId": "d31e27f9-f34b-42e1-ffaa-ff200fa0c382"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your text:In the heart of a small town, there was an old, forgotten library. The building was grand, with towering bookshelves that seemed to touch the sky and windows that let in rays of golden sunlight. But over the years, people had stopped visiting. The books collected dust, and the once vibrant atmosphere had turned silent.  Lena, a young girl with a curious mind, stumbled upon this library one rainy afternoon. She pushed open the creaky door and stepped inside, her eyes widening in awe. Rows and rows of books greeted her, each one holding secrets waiting to be discovered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarize(text)\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a6LgLUd4myZ",
        "outputId": "5a01bfb8-aa53-43a2-f259-d0e3d51f5574"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Similarity Scores:\n",
            "Sentence 1: 0.9999999999999993\n",
            "Sentence 2: 0.602193791596494\n",
            "\n",
            "Summary:\n",
            "In the heart of a small town, there was an old, forgotten library. The building was grand, with towering bookshelves that seemed to touch the sky and windows that let in rays of golden sunlight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M74LGLRC4oTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}